{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_export_articles(terms=None,export_suffix=None,max_articles=1000,export=True):\n",
    "    \n",
    "    '''\n",
    "    Scrapes Pubmed for numerous attributes and returns the result as a dataframe,\n",
    "    exporting it as a csv unless noted. Uses Biopython's Entrez Function to send requests to Pubmed.\n",
    "    \n",
    "    \n",
    "    Takes in the following arguments:\n",
    "    \n",
    "    - terms: a list or string object. The term(s) to search pubmed for.\n",
    "    \n",
    "    - export_suffix: optional. A term that allows you to control what you want\n",
    "    the exported file to have at the end. The default naming structure is \n",
    "    pubmed_abstracts_export_{}_{}.csv, where the first bracket is the suffix \n",
    "    and the second is the date of export.\n",
    "    \n",
    "    - max_articles: an integer, default is 1000. The max number of articles to return when searching pubmed.\n",
    "    \n",
    "    - export: boolean, whether or not you want the resulting dataframe exported as a csv. Default is True. \n",
    "    \n",
    "    Credit for the search and fetch_details helper functions, which wrapped the Biopython Entrez function \n",
    "    in a clean wrapper, goes to Marco Bonzani, with this blogpost:\n",
    "    https://marcobonzanini.com/2015/01/12/searching-pubmed-with-python/\n",
    "    \n",
    "    \n",
    "    Currently the following article attributes are exported from pubmed:\n",
    "    \n",
    "    - PMID: Pubmed Article ID\n",
    "    - med_type: type of medication/treatment used in the study\n",
    "    - keywords: relevant keywords for article searching\n",
    "    - date: date published, and if absent, completed\n",
    "    - language: language of paper. 'eng' == English\n",
    "    - journal_title: title of the publishing journal\n",
    "    - ISSN: Identifier for the publishing journal\n",
    "    - article_title: article title\n",
    "    - abstract: article abstract\n",
    "    - authors: authors of paper, separated by ';'\n",
    "    \n",
    "    Relevant Websites:\n",
    "    Pubmed: https://www.ncbi.nlm.nih.gov/pubmed/\n",
    "    \n",
    "    This funciton has the following dependencies:\n",
    "    \n",
    "    - Pandas\n",
    "    - Biopython\n",
    "    - Numpy\n",
    "    - urllib\n",
    "    - json\n",
    "    - datetime\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    from Bio import Entrez\n",
    "    from Bio import Entrez\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from urllib.request import urlopen, Request\n",
    "    from urllib.parse import urlencode\n",
    "    import json\n",
    "    \n",
    "    from datetime import datetime\n",
    "    \n",
    "    if isinstance(terms,str):\n",
    "        new_list = list()\n",
    "        new_list.append(terms)\n",
    "        terms = new_list\n",
    "    elif terms == None:\n",
    "        raise ValueError(\"There must be a search term. Please specify one or more using the terms parameter.\")\n",
    "    elif (isinstance(terms, tuple))  | (isinstance(terms, dict)):\n",
    "        raise ValueError(\"Please enter the search terms in a list.\")\n",
    "        \n",
    "    \n",
    "    # helper functions from https://marcobonzanini.com/2015/01/12/searching-pubmed-with-python/\n",
    "    def search(query,max_articles=max_articles):\n",
    "        Entrez.email = 'youremail@example.com'\n",
    "        handle = Entrez.esearch(db='pubmed', \n",
    "                                sort='relevance', \n",
    "                                retmax=max_articles, # the number of papers you want to return \n",
    "                                retmode='xml', \n",
    "                                term=query)\n",
    "        results = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        return results\n",
    "\n",
    "\n",
    "    def fetch_details(id_list):\n",
    "        ids = ','.join(id_list)\n",
    "        Entrez.email = 'youremail@example.com'\n",
    "        handle = Entrez.efetch(db='pubmed',\n",
    "                               retmode='xml',\n",
    "                               id=ids)\n",
    "        results = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        return results\n",
    "\n",
    "    attribs = ['PMID','med_type','keywords','date','language','journal_title','ISSN','article_title','abstract','authors']\n",
    "    \n",
    "    #create final dataframe for all search terms\n",
    "    export_df = pd.DataFrame(columns = attribs)\n",
    "\n",
    "\n",
    "    for i in range(len(terms)):\n",
    "\n",
    "        search_df = pd.DataFrame( columns = attribs)\n",
    "\n",
    "        results = search(terms[i],max_articles=max_articles)\n",
    "\n",
    "        disease = terms[i]\n",
    "\n",
    "        #handle empty results\n",
    "        try:\n",
    "            id_list = results['IdList']\n",
    "            papers = fetch_details(id_list)\n",
    "        except RuntimeError:\n",
    "            print(\"no results found for search term: {}\".format(disease))\n",
    "            continue\n",
    "\n",
    "        #get number of papers found\n",
    "        n_papers = len(papers['PubmedArticle'])\n",
    "\n",
    "        print(\"Search found {} results\".format(n_papers))\n",
    "        print('')\n",
    "\n",
    "        for j in range(n_papers):\n",
    "\n",
    "            #create empty dataframe for single paper\n",
    "            paper_df = pd.DataFrame()\n",
    "\n",
    "            #get type of medication/treatment/chemical used\n",
    "            try:\n",
    "                med_type = str(papers['PubmedArticle'][j]['MedlineCitation']['ChemicalList'][0]['NameOfSubstance'])\n",
    "            except KeyError:\n",
    "                med_type = ''\n",
    "\n",
    "            #get keywords\n",
    "            keywords = []\n",
    "            try:\n",
    "                for k in range(len(papers['PubmedArticle'][j]['MedlineCitation']['KeywordList'][0])):\n",
    "                    keyword = \"\".join(char for char in str(papers['PubmedArticle'][j]['MedlineCitation']['KeywordList'][0][k]))\n",
    "                    keywords.append(keyword)\n",
    "                clean_keywords = \",\".join(char for char in keywords)\n",
    "            except IndexError:\n",
    "                clean_keywords = ''\n",
    "\n",
    "            #get date of publish\n",
    "            try:\n",
    "                year = papers['PubmedArticle'][j]['MedlineCitation']['Article']['ArticleDate'][0]['Year']\n",
    "                month = papers['PubmedArticle'][j]['MedlineCitation']['Article']['ArticleDate'][0]['Month']\n",
    "                day = papers['PubmedArticle'][j]['MedlineCitation']['Article']['ArticleDate'][0]['Day']\n",
    "            except IndexError:\n",
    "                try:\n",
    "                    date_comp = papers['PubmedArticle'][j]['MedlineCitation']['DateCompleted'] \n",
    "                    year = date_comp['Year']\n",
    "                    month = date_comp['Month']\n",
    "                    day = date_comp['Day']\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        year = papers['PubmedArticle'][j]['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Year']\n",
    "                        month = papers['PubmedArticle'][j]['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Month']\n",
    "                        day = None\n",
    "                    except KeyError:\n",
    "                        year = None\n",
    "                        month = None\n",
    "                        day = None\n",
    "\n",
    "            #clean and combine dates\n",
    "            try:\n",
    "                date = str(year + '/' + month + '/' + day)\n",
    "                #print(date)\n",
    "            except TypeError:\n",
    "                try:\n",
    "                    date = str(year + '/' + month + '/' + '1')\n",
    "                except TypeError:\n",
    "                    date = None\n",
    "                #print(date)\n",
    "\n",
    "\n",
    "            #get authors\n",
    "            author_names = []\n",
    "            try:\n",
    "                authors = papers['PubmedArticle'][j]['MedlineCitation']['Article']['AuthorList'] \n",
    "                for i in range(len(authors)):\n",
    "                    first = authors[i]['ForeName']\n",
    "                    last = authors[i]['LastName']\n",
    "                    full_name = first + ' ' + last\n",
    "                    author_names.append(full_name)\n",
    "\n",
    "                all_author_names = \";\".join(author for author in author_names)\n",
    "\n",
    "            except KeyError:\n",
    "                all_author_names = None\n",
    "\n",
    "            #get paper language\n",
    "            lang = str(papers['PubmedArticle'][j]['MedlineCitation']['Article']['Language'])\n",
    "\n",
    "            # Get Journal title\n",
    "            journal_title = str(papers['PubmedArticle'][j]['MedlineCitation']['Article']['Journal']['Title'])\n",
    "            #print(journal_title)\n",
    "\n",
    "            # Get ISSN ID for Journal\n",
    "            try:\n",
    "                ISSN = str(papers['PubmedArticle'][j]['MedlineCitation']['Article']['Journal']['ISSN'])\n",
    "            except KeyError:\n",
    "                ISSN = ''\n",
    "\n",
    "            # Get title\n",
    "            title = \"\".join(char for char in list(papers['PubmedArticle'][j]['MedlineCitation']['Article']['ArticleTitle']))\n",
    "\n",
    "            # get full abstract\n",
    "            try:\n",
    "                abstract = \"\".join(line for line in papers['PubmedArticle'][j]['MedlineCitation']['Article']['Abstract']['AbstractText'])\n",
    "            except KeyError:\n",
    "                abstract = ''\n",
    "                \n",
    "            #get pubmed ID\n",
    "            pmid = str(papers['PubmedArticle'][j]['MedlineCitation']['PMID'])\n",
    "\n",
    "            # bring everything in dataframe\n",
    "            paper_df['PMID'] = pd.Series(pmid)\n",
    "            paper_df['med_type'] = pd.Series(med_type)\n",
    "            paper_df['keywords'] = pd.Series(clean_keywords)\n",
    "            paper_df['date'] = pd.Series(date)\n",
    "            paper_df['language'] = pd.Series(lang)\n",
    "            paper_df['journal_title'] = pd.Series(journal_title)\n",
    "            paper_df['ISSN'] = pd.Series(ISSN)\n",
    "            paper_df['article_title'] = pd.Series(title)\n",
    "            paper_df['abstract'] = pd.Series(abstract)\n",
    "            paper_df['disease'] = pd.Series(disease)\n",
    "            paper_df['authors'] = pd.Series(all_author_names)\n",
    "\n",
    "            #add into existing dataframe for search term\n",
    "            search_df = pd.concat([search_df, paper_df],ignore_index=True)\n",
    "\n",
    "            #printing out progress for every 10% of terms\n",
    "            if j % round((n_papers *.25),0) == 0:\n",
    "                print(\"Article #{} processed\".format(j))\n",
    "                print('---------')\n",
    "            elif j == (n_papers - 1):\n",
    "                print(\"Article #{} processed\".format(j))\n",
    "                print(\"All articles for {} term processed.\".format(disease))\n",
    "                print('---------')\n",
    "\n",
    "        #adding to final search dataframe\n",
    "        export_df = pd.concat([export_df,search_df],ignore_index=True)\n",
    "\n",
    "    print(\"All terms processed.\")        \n",
    "    \n",
    "    if export:\n",
    "        export_df.to_csv(\"pubmed_abstracts_export_{}_{}.csv\".format(batch,datetime.today().strftime('%Y-%m-%d')))\n",
    "\n",
    "    print(export_df.head())\n",
    "    \n",
    "    return export_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all batch 1 terms\n",
    "search_terms = ['fever','diabetes type 2','pancreatic cancer',\"alzheimers\",'lupus',\"parkinsons\",'dementia',\n",
    "                'breast cancer','high blood pressure','heart disease',\"lymphoma\",'clinical depression',\n",
    "                \"bipolar disorder\",'arthritis','lime disease','amyotrophic lateral sclerosis',\n",
    "                'obesity',\"acquired immunodeficiency syndrome\",'thyroid cancer','kidney failure',\n",
    "               \"multiple sclerosis\",\"lung cancer\",'melanoma','Non-melanoma skin cancer','prostate cancer','Colorectal cancer',\n",
    "                'non-hodgkin lymphoma','insomnia','anxiety disorder','dystonia','chronic lower respitory disease','influenza','stroke','hepatitis b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for fever term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for diabetes type 2 term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for pancreatic cancer term processed.\n",
      "---------\n",
      "Search found 1999 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #1998 processed\n",
      "All articles for alzheimers term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for lupus term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for parkinsons term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for dementia term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for breast cancer term processed.\n",
      "---------\n",
      "Search found 1996 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #1995 processed\n",
      "All articles for high blood pressure term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for heart disease term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for lymphoma term processed.\n",
      "---------\n",
      "Search found 1999 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #1998 processed\n",
      "All articles for clinical depression term processed.\n",
      "---------\n",
      "Search found 1998 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #1997 processed\n",
      "All articles for bipolar disorder term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for arthritis term processed.\n",
      "---------\n",
      "Search found 311 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #310 processed\n",
      "All articles for lime disease term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for amyotrophic lateral sclerosis term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for obesity term processed.\n",
      "---------\n",
      "Search found 1999 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #1998 processed\n",
      "All articles for acquired immunodeficiency syndrome term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for thyroid cancer term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for kidney failure term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for multiple sclerosis term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for lung cancer term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for melanoma term processed.\n",
      "---------\n",
      "Search found 1998 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #1997 processed\n",
      "All articles for Non-melanoma skin cancer term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for prostate cancer term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for Colorectal cancer term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for non-hodgkin lymphoma term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for insomnia term processed.\n",
      "---------\n",
      "Search found 1999 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #1998 processed\n",
      "All articles for anxiety disorder term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for dystonia term processed.\n",
      "---------\n",
      "no results found for search term: chronic lower respitory disease\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for influenza term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for stroke term processed.\n",
      "---------\n",
      "Search found 2000 results\n",
      "\n",
      "Article #0 processed\n",
      "---------\n",
      "Article #200 processed\n",
      "---------\n",
      "Article #400 processed\n",
      "---------\n",
      "Article #600 processed\n",
      "---------\n",
      "Article #800 processed\n",
      "---------\n",
      "Article #1000 processed\n",
      "---------\n",
      "Article #1200 processed\n",
      "---------\n",
      "Article #1400 processed\n",
      "---------\n",
      "Article #1600 processed\n",
      "---------\n",
      "Article #1800 processed\n",
      "---------\n",
      "Article #1999 processed\n",
      "All articles for hepatitis b term processed.\n",
      "---------\n",
      "All terms processed.\n",
      "                                       Article_title        Date       ISSN  \\\n",
      "0  Predictive Factors of Fever After Aneurysmal S...  2018/03/13  1878-8769   \n",
      "1                  Tri-phasic fever in dengue fever.  2018/02/08  1758-1133   \n",
      "2  Periconceptional maternal fever, folic acid in...  2017/11/02  1873-2585   \n",
      "3                                 Neutropenic Fever.  2018/01/04  1558-1977   \n",
      "4  Detection of human parvovirus B19 in serum sam...  2017/09/22  1878-3511   \n",
      "\n",
      "       PMID                                           abstract article_title  \\\n",
      "0  29548963  Fever is relatively common and worsens neurolo...           NaN   \n",
      "1  29419375  Dengue fever is an acute febrile illness with ...           NaN   \n",
      "2  29133009  Previous studies have shown an association bet...           NaN   \n",
      "3  29078933  Fever is a common presenting complaint among a...           NaN   \n",
      "4  28951104  It has been demonstrated that infection with h...           NaN   \n",
      "\n",
      "                                             authors date disease  \\\n",
      "0  Yung Ki Park;Hyeong-Joong Yi;Kyu-Sun Choi;Youn...  NaN   fever   \n",
      "1  Pradeepa H D;Sathish B Rao;Ganaraj B;Gopalakri...  NaN   fever   \n",
      "2  Stephen M Kerr;Samantha E Parker;Allen A Mitch...  NaN   fever   \n",
      "3                       Lindsey White;Michael Ybarra  NaN   fever   \n",
      "4  Tony Bokalanga Wawina;Olivier Mbaya Tshiani;St...  NaN   fever   \n",
      "\n",
      "                                       journal_title  \\\n",
      "0                                 World neurosurgery   \n",
      "1                                    Tropical doctor   \n",
      "2                             Annals of epidemiology   \n",
      "3       Hematology/oncology clinics of North America   \n",
      "4  International journal of infectious diseases :...   \n",
      "\n",
      "                                            keywords language  \\\n",
      "0  Anterior communicating artery aneurysm,Brain i...  ['eng']   \n",
      "1  24 hours,Continuous,conventional monitoring,de...  ['eng']   \n",
      "2  Fever,Folic acid,Neural tube defects,Spina bifida  ['eng']   \n",
      "3  Bacterial infection,Neutropenic fever,Risk str...  ['eng']   \n",
      "4  Democratic Republic of the Congo,IgM antibody,...  ['eng']   \n",
      "\n",
      "                med_type  \n",
      "0           Antipyretics  \n",
      "1                         \n",
      "2      Vitamin B Complex  \n",
      "3  Anti-Bacterial Agents  \n",
      "4      Antibodies, Viral  \n"
     ]
    }
   ],
   "source": [
    "test_df = search_and_export_articles(terms=search_terms,export_suffix=\"all\",max_articles=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64299 entries, 0 to 64298\n",
      "Data columns (total 13 columns):\n",
      "Article_title    64299 non-null object\n",
      "Date             64202 non-null object\n",
      "ISSN             64299 non-null object\n",
      "PMID             64299 non-null object\n",
      "abstract         64299 non-null object\n",
      "article_title    0 non-null object\n",
      "authors          61579 non-null object\n",
      "date             0 non-null object\n",
      "disease          64299 non-null object\n",
      "journal_title    64299 non-null object\n",
      "keywords         64299 non-null object\n",
      "language         64299 non-null object\n",
      "med_type         64299 non-null object\n",
      "dtypes: object(13)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Date</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>PMID</th>\n",
       "      <th>abstract</th>\n",
       "      <th>article_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>disease</th>\n",
       "      <th>journal_title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>language</th>\n",
       "      <th>med_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Predictive Factors of Fever After Aneurysmal S...</td>\n",
       "      <td>2018/03/13</td>\n",
       "      <td>1878-8769</td>\n",
       "      <td>29548963</td>\n",
       "      <td>Fever is relatively common and worsens neurolo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yung Ki Park;Hyeong-Joong Yi;Kyu-Sun Choi;Youn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fever</td>\n",
       "      <td>World neurosurgery</td>\n",
       "      <td>Anterior communicating artery aneurysm,Brain i...</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>Antipyretics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tri-phasic fever in dengue fever.</td>\n",
       "      <td>2018/02/08</td>\n",
       "      <td>1758-1133</td>\n",
       "      <td>29419375</td>\n",
       "      <td>Dengue fever is an acute febrile illness with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pradeepa H D;Sathish B Rao;Ganaraj B;Gopalakri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fever</td>\n",
       "      <td>Tropical doctor</td>\n",
       "      <td>24 hours,Continuous,conventional monitoring,de...</td>\n",
       "      <td>['eng']</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Periconceptional maternal fever, folic acid in...</td>\n",
       "      <td>2017/11/02</td>\n",
       "      <td>1873-2585</td>\n",
       "      <td>29133009</td>\n",
       "      <td>Previous studies have shown an association bet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stephen M Kerr;Samantha E Parker;Allen A Mitch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fever</td>\n",
       "      <td>Annals of epidemiology</td>\n",
       "      <td>Fever,Folic acid,Neural tube defects,Spina bifida</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>Vitamin B Complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutropenic Fever.</td>\n",
       "      <td>2018/01/04</td>\n",
       "      <td>1558-1977</td>\n",
       "      <td>29078933</td>\n",
       "      <td>Fever is a common presenting complaint among a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lindsey White;Michael Ybarra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fever</td>\n",
       "      <td>Hematology/oncology clinics of North America</td>\n",
       "      <td>Bacterial infection,Neutropenic fever,Risk str...</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>Anti-Bacterial Agents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detection of human parvovirus B19 in serum sam...</td>\n",
       "      <td>2017/09/22</td>\n",
       "      <td>1878-3511</td>\n",
       "      <td>28951104</td>\n",
       "      <td>It has been demonstrated that infection with h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tony Bokalanga Wawina;Olivier Mbaya Tshiani;St...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fever</td>\n",
       "      <td>International journal of infectious diseases :...</td>\n",
       "      <td>Democratic Republic of the Congo,IgM antibody,...</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>Antibodies, Viral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Article_title        Date       ISSN  \\\n",
       "0  Predictive Factors of Fever After Aneurysmal S...  2018/03/13  1878-8769   \n",
       "1                  Tri-phasic fever in dengue fever.  2018/02/08  1758-1133   \n",
       "2  Periconceptional maternal fever, folic acid in...  2017/11/02  1873-2585   \n",
       "3                                 Neutropenic Fever.  2018/01/04  1558-1977   \n",
       "4  Detection of human parvovirus B19 in serum sam...  2017/09/22  1878-3511   \n",
       "\n",
       "       PMID                                           abstract article_title  \\\n",
       "0  29548963  Fever is relatively common and worsens neurolo...           NaN   \n",
       "1  29419375  Dengue fever is an acute febrile illness with ...           NaN   \n",
       "2  29133009  Previous studies have shown an association bet...           NaN   \n",
       "3  29078933  Fever is a common presenting complaint among a...           NaN   \n",
       "4  28951104  It has been demonstrated that infection with h...           NaN   \n",
       "\n",
       "                                             authors date disease  \\\n",
       "0  Yung Ki Park;Hyeong-Joong Yi;Kyu-Sun Choi;Youn...  NaN   fever   \n",
       "1  Pradeepa H D;Sathish B Rao;Ganaraj B;Gopalakri...  NaN   fever   \n",
       "2  Stephen M Kerr;Samantha E Parker;Allen A Mitch...  NaN   fever   \n",
       "3                       Lindsey White;Michael Ybarra  NaN   fever   \n",
       "4  Tony Bokalanga Wawina;Olivier Mbaya Tshiani;St...  NaN   fever   \n",
       "\n",
       "                                       journal_title  \\\n",
       "0                                 World neurosurgery   \n",
       "1                                    Tropical doctor   \n",
       "2                             Annals of epidemiology   \n",
       "3       Hematology/oncology clinics of North America   \n",
       "4  International journal of infectious diseases :...   \n",
       "\n",
       "                                            keywords language  \\\n",
       "0  Anterior communicating artery aneurysm,Brain i...  ['eng']   \n",
       "1  24 hours,Continuous,conventional monitoring,de...  ['eng']   \n",
       "2  Fever,Folic acid,Neural tube defects,Spina bifida  ['eng']   \n",
       "3  Bacterial infection,Neutropenic fever,Risk str...  ['eng']   \n",
       "4  Democratic Republic of the Congo,IgM antibody,...  ['eng']   \n",
       "\n",
       "                med_type  \n",
       "0           Antipyretics  \n",
       "1                         \n",
       "2      Vitamin B Complex  \n",
       "3  Anti-Bacterial Agents  \n",
       "4      Antibodies, Viral  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
